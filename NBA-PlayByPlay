import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import warnings
warnings.filterwarnings('ignore')

class NBAPlayByPlayAnalyzer:
    """
    Analizador avanzado de datos NBA Play-by-Play
    DiseÃ±ado para trabajar con el dataset de Kaggle NBA Play-by-Play Data 1997-2023
    """
    
    def __init__(self):
        self.data = None
        self.models = {}
        self.encoders = {}
        self.scalers = {}
        self.feature_importance = {}
        
        # ConfiguraciÃ³n de tipos de jugadas tÃ­picas en NBA
        self.shot_types = ['2PT Field Goal', '3PT Field Goal', 'Free Throw']
        self.play_categories = {
            'SHOT': ['field goal', 'shot', 'dunk', 'layup', 'jumper'],
            'TURNOVER': ['turnover', 'steal', 'bad pass', 'lost ball'],
            'FOUL': ['foul', 'flagrant', 'technical'],
            'REBOUND': ['rebound', 'defensive rebound', 'offensive rebound'],
            'ASSIST': ['assist'],
            'TIMEOUT': ['timeout'],
            'SUBSTITUTION': ['enters', 'substitution']
        }
    
    def load_real_data(self, file_path):
        """
        Carga el dataset real de NBA play-by-play
        Esperamos columnas como: game_id, period, time, team, player, event_type, description, etc.
        """
        try:
            print("ðŸ€ Cargando datos reales de NBA...")
            self.data = pd.read_csv(file_path)
            
            print(f"âœ… Datos cargados exitosamente!")
            print(f"   ðŸ“Š Total de registros: {len(self.data):,}")
            print(f"   ðŸ“… Columnas disponibles: {list(self.data.columns)}")
            
            # Mostrar informaciÃ³n bÃ¡sica del dataset
            if 'season' in self.data.columns:
                seasons = self.data['season'].unique()
                print(f"   ðŸ—“ï¸  Temporadas: {min(seasons)} - {max(seasons)}")
            
            if 'team' in self.data.columns or 'team_name' in self.data.columns:
                team_col = 'team' if 'team' in self.data.columns else 'team_name'
                teams = self.data[team_col].nunique()
                print(f"   ðŸ€ Equipos Ãºnicos: {teams}")
            
            return self.data.head()
            
        except Exception as e:
            print(f"âŒ Error al cargar los datos: {e}")
            print("ðŸ’¡ Generando datos de ejemplo para demostraciÃ³n...")
            return self._generate_sample_data()
    
    def _generate_sample_data(self):
        """Genera datos de ejemplo con estructura similar al dataset real"""
        np.random.seed(42)
        n_games = 100
        n_plays_per_game = 200
        n_total = n_games * n_plays_per_game
        
        # Equipos y jugadores reales
        teams = ['LAL', 'GSW', 'BOS', 'MIA', 'BRK', 'MIL', 'PHX', 'DEN', 'DAL', 'PHI']
        players = {
            'LAL': ['LeBron James', 'Anthony Davis', 'Russell Westbrook'],
            'GSW': ['Stephen Curry', 'Klay Thompson', 'Draymond Green'],
            'BOS': ['Jayson Tatum', 'Jaylen Brown', 'Marcus Smart'],
            'MIA': ['Jimmy Butler', 'Bam Adebayo', 'Tyler Herro'],
            'BRK': ['Kevin Durant', 'Kyrie Irving', 'Ben Simmons']
        }
        
        # Expandir jugadores para todos los equipos
        all_players = []
        for team in teams:
            if team in players:
                all_players.extend(players[team])
            else:
                all_players.extend([f'Player_{team}_1', f'Player_{team}_2', f'Player_{team}_3'])
        
        # Generar datos estructurados
        data = []
        for game_id in range(1, n_games + 1):
            home_team = np.random.choice(teams)
            away_team = np.random.choice([t for t in teams if t != home_team])
            
            for play_num in range(n_plays_per_game):
                # Simular progresiÃ³n del tiempo
                period = min(4, max(1, int(play_num / 50) + 1))
                time_remaining = max(0, 720 - (play_num % 50) * 15)
                
                # Seleccionar equipo y jugador
                current_team = np.random.choice([home_team, away_team])
                current_player = np.random.choice(all_players)
                
                # Tipo de jugada con probabilidades realistas
                event_types = ['shot', 'miss', 'made', 'foul', 'turnover', 'rebound', 'assist', 'timeout']
                event_weights = [0.25, 0.15, 0.15, 0.15, 0.10, 0.10, 0.05, 0.05]
                event_type = np.random.choice(event_types, p=event_weights)
                
                # Detalles especÃ­ficos segÃºn el tipo de jugada
                shot_type = None
                points = 0
                success = 0
                
                if event_type in ['shot', 'made', 'miss']:
                    shot_type = np.random.choice(['2PT', '3PT', 'FT'], p=[0.6, 0.3, 0.1])
                    if event_type == 'made':
                        success = 1
                        points = 3 if shot_type == '3PT' else 2 if shot_type == '2PT' else 1
                    elif event_type == 'shot':
                        success = np.random.choice([0, 1], p=[0.55, 0.45])
                        if success:
                            points = 3 if shot_type == '3PT' else 2 if shot_type == '2PT' else 1
                
                # Contexto del juego
                score_diff = np.random.randint(-25, 26)
                
                data.append({
                    'game_id': f'00{game_id:05d}',
                    'season': 2023,
                    'period': period,
                    'time_remaining': time_remaining,
                    'team': current_team,
                    'opponent': away_team if current_team == home_team else home_team,
                    'player': current_player,
                    'event_type': event_type,
                    'shot_type': shot_type,
                    'points': points,
                    'success': success,
                    'score_diff': score_diff,
                    'home_away': 'HOME' if current_team == home_team else 'AWAY',
                    'clutch_time': 1 if period >= 4 and time_remaining <= 300 else 0
                })
        
        self.data = pd.DataFrame(data)
        print(f"âœ… Datos de ejemplo generados: {len(self.data):,} jugadas")
        return self.data.head()
    
    def preprocess_data(self):
        """Preprocesa los datos para anÃ¡lisis y modelado"""
        print("ðŸ”„ Preprocesando datos...")
        
        # Limpiar datos nulos en columnas crÃ­ticas
        critical_cols = ['player', 'team', 'event_type']
        initial_rows = len(self.data)
        self.data = self.data.dropna(subset=critical_cols)
        print(f"   ðŸ§¹ Filas eliminadas por datos nulos: {initial_rows - len(self.data):,}")
        
        # Crear encoders para variables categÃ³ricas
        categorical_cols = ['team', 'opponent', 'player', 'event_type', 'shot_type', 'home_away']
        
        for col in categorical_cols:
            if col in self.data.columns:
                le = LabelEncoder()
                # Manejar valores nulos
                self.data[col] = self.data[col].fillna('UNKNOWN')
                self.data[f'{col}_encoded'] = le.fit_transform(self.data[col])
                self.encoders[col] = le
        
        # Crear features adicionales
        self.data['time_factor'] = self.data['time_remaining'] / 720
        self.data['period_factor'] = self.data['period'] / 4
        
        # Feature de momentum (diferencia de puntos normalizada)
        self.data['momentum'] = np.tanh(self.data['score_diff'] / 10)
        
        # Identificar situaciones crÃ­ticas
        self.data['critical_moment'] = (
            (self.data['period'] >= 4) & 
            (self.data['time_remaining'] <= 300) & 
            (abs(self.data['score_diff']) <= 5)
        ).astype(int)
        
        print("âœ… Preprocesamiento completado")
        print(f"   ðŸ“Š Filas finales: {len(self.data):,}")
        
    def train_predictive_models(self):
        """Entrena modelos predictivos para diferentes aspectos del juego"""
        try:
            print("ðŸ¤– Entrenando modelos predictivos...")
            
            # Features para predicciÃ³n
            feature_cols = [
                'team_encoded', 'opponent_encoded', 'player_encoded',
                'period', 'time_factor', 'score_diff', 'home_away_encoded',
                'clutch_time', 'momentum', 'critical_moment'
            ]
            
            # Filtrar features disponibles
            available_features = [col for col in feature_cols if col in self.data.columns]
            X = self.data[available_features].fillna(0)
            
            # Escalar features numÃ©ricas
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)
            self.scalers['features'] = scaler
            
            models_to_train = [
                ('event_type', 'event_type_encoded', 'classification'),
                ('success', 'success', 'classification'),
                ('points', 'points', 'regression')
            ]
            
            for model_name, target_col, model_type in models_to_train:
                if target_col not in self.data.columns:
                    continue
                    
                y = self.data[target_col].fillna(0)
                
                # Usar stratify solo para clasificaciÃ³n
                if model_type == 'classification':
                    X_train, X_test, y_train, y_test = train_test_split(
                        X_scaled, y, test_size=0.2, random_state=42, stratify=y
                    )
                else:
                    X_train, X_test, y_train, y_test = train_test_split(
                        X_scaled, y, test_size=0.2, random_state=42
                    )
                
                # Seleccionar y entrenar el modelo adecuado
                if model_type == 'classification':
                    model = RandomForestClassifier(
                        n_estimators=100, 
                        random_state=42, 
                        n_jobs=-1
                    )
                else:  # regression
                    model = RandomForestRegressor(
                        n_estimators=100, 
                        random_state=42, 
                        n_jobs=-1
                    )
                
                # Entrenar modelo
                model.fit(X_train, y_train)
                predictions = model.predict(X_test)
                
                # Evaluar modelo
                if model_type == 'classification':
                    accuracy = accuracy_score(y_test, predictions)
                    print(f"   âœ… {model_name}: PrecisiÃ³n = {accuracy:.3f}")
                    if model_name == 'event_type':
                        print(f"   ðŸ“Š Reporte detallado:\n{classification_report(y_test, predictions)}")
                else:
                    mse = np.mean((y_test - predictions) ** 2)
                    rmse = np.sqrt(mse)
                    print(f"   âœ… {model_name}: RMSE = {rmse:.3f}")
                
                # Guardar modelo y mÃ©tricas
                self.models[model_name] = model
                self.feature_importance[model_name] = dict(zip(
                    available_features, 
                    model.feature_importances_
                ))
            
            print("ðŸŽ¯ Modelos entrenados exitosamente!")
            
        except Exception as e:
            print(f"âŒ Error durante el entrenamiento: {str(e)}")

# Crear el analizador
analyzer = NBAPlayByPlayAnalyzer()

# Generar datos de ejemplo (en tu caso, usarÃ­as: analyzer.load_real_data('path_to_your_dataset.csv'))
sample_data = analyzer._generate_sample_data()
print("\nðŸ“‹ Primeras 5 filas del dataset:")
print(sample_data)

# Preprocesar datos
analyzer.preprocess_data()

# Entrenar modelos
analyzer.train_predictive_models()